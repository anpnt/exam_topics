{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779705b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exam DP-700 topic 1 question 6 discussion\n",
      "HOTSPOT -\n",
      "You have a Fabric workspace that contains a warehouse named DW1. DW1 contains the following tables and columns.\n",
      "https://img.examtopics.com/dp-700/image1.png\n",
      "You need to create an output that presents the summarized values of all the order quantities by year and product. The results must include a summary of the order quantities at the year level for all the products.\n",
      "How should you complete the code? To answer, select the appropriate options in the answer area.\n",
      "NOTE: Each correct selection is worth one point.\n",
      "https://img.examtopics.com/dp-700/image2.png\n",
      "Highly Voted comment found!\n",
      "SELECT YEAR\n",
      "ROLLUP(YEAR(SO.ModifiedDATE), P.Name)\n",
      "************************\n",
      "Highly Voted comment found!\n",
      "SELECT YEAR\n",
      "\n",
      "\n",
      "Grouping Sets: Best answer. No extra stuff. Just what we want\n",
      "Cube: Lots of extra combinations. Has a row with the total for all years and all products, and rows with the total for each product for all years. \n",
      "Rollup: Has the unnecessary total of all products and all years\n",
      "Normal Group by: No summary at the year level for all products.\n",
      "\n",
      "https://learn.microsoft.com/en-us/sql/t-sql/queries/select-group-by-transact-sql?view=sql-server-ver16\n",
      "************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "url = \"https://www.examtopics.com/discussions/microsoft/view/153079-exam-dp-700-topic-1-question-6-discussion/\"\n",
    "with requests.Session() as session:\n",
    "    # Set up retries\n",
    "    session.headers.update({'User-Agent': 'Mozilla/5.0'})\n",
    "    response = session.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the div with the \"new-comment-box\" class\n",
    "    div = soup.find(\"div\", class_=\"new-comment-box\")\n",
    "\n",
    "    # Extract the value of the data-title attribute\n",
    "    if div and \"data-title\" in div.attrs:\n",
    "        data_title = div[\"data-title\"]\n",
    "\n",
    "    p_tag = soup.find('p', class_='card-text')\n",
    "\n",
    "    # Extract text and replace <br/> with new lines\n",
    "    text_parts = []\n",
    "    for element in p_tag.contents:\n",
    "        if isinstance(element, str):\n",
    "            text_parts.append(element)\n",
    "        elif element.name == 'br':\n",
    "            text_parts.append('\\n')\n",
    "        elif element.name == 'img':\n",
    "            text_parts.append(element['src'])\n",
    "\n",
    "    # Combine text parts into a single string\n",
    "    question_str = ''.join(text_parts)\n",
    "\n",
    "    # Find all answer choices and remove trailing blanks and new lines\n",
    "    answer_choices = [li.text.strip().replace('\\n', '').replace('\\r', '') for li in soup.find_all('li', class_='multi-choice-item')]\n",
    "\n",
    "    # combine all answer choices into a single string and new line separated\n",
    "    answer_choices_str = '\\n'.join(answer_choices)\n",
    "    # concat the data_title, question_str and answer_choices_str\n",
    "    final_str = f\"{data_title}\\n{question_str}\\n{answer_choices_str}\"\n",
    "\n",
    "    # Processing the text to remove the extra spaces:\n",
    "    lines = final_str.splitlines()  # Split the text into lines\n",
    "    formatted_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        # Strip extra spaces and format neatly\n",
    "        stripped = \" \".join(line.split())\n",
    "        if stripped:  # To ignore empty lines\n",
    "            formatted_lines.append(stripped)\n",
    "\n",
    "    # Join the formatted lines back together\n",
    "    formatted_text = \"\\n\".join(formatted_lines)\n",
    "\n",
    "    # Find all badges with \"Highly Voted\"\n",
    "    highly_voted_badges = soup.find_all(\"span\", class_=\"badge badge-primary\")\n",
    "\n",
    "    comment_str = \"\"\n",
    "    for badge in highly_voted_badges:\n",
    "        # Check if the badge contains the text \"Highly Voted\"\n",
    "        if \"Highly Voted\" in badge.text:\n",
    "            # Find the parent comment-container\n",
    "            comment_container = badge.find_parent(\"div\", class_=\"comment-container\")\n",
    "            if comment_container:\n",
    "                # Extract the text from the corresponding comment-content\n",
    "                comment_content = comment_container.find(\"div\", class_=\"comment-content\")\n",
    "                if comment_content:\n",
    "                    comment_str += \"Highly Voted comment found!\" + \"\\n\" + comment_content.text.strip() + \"\\n\" + \"******************************\" + \"\\n\" \n",
    "    # Combine the formatted text and comment string\n",
    "    final_output = f\"{formatted_text}\\n{comment_str}\"\n",
    "    print(final_output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd03f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Read the Excel file and get the column with URLs\n",
    "excel_file = r\"azure_examtopics_20250430.xlsx\"  # Replace with your Excel file name\n",
    "url_column = \"link\"  # Replace with the column name containing URLs\n",
    "df = pd.read_excel(excel_file)\n",
    "# filter exam = DP-700\n",
    "df = df[df['exam'] == 'Exam DP-700 ']\n",
    "\n",
    "# Open a text file to write the final output\n",
    "output_file = \"output.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    for url in df[url_column]:\n",
    "        try:\n",
    "            with requests.Session() as session:\n",
    "                # Set up retries\n",
    "                session.headers.update({'User-Agent': 'Mozilla/5.0'})\n",
    "                response = session.get(url)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                # Parse the HTML content\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "                # Find the div with the \"new-comment-box\" class\n",
    "                div = soup.find(\"div\", class_=\"new-comment-box\")\n",
    "\n",
    "                # Extract the value of the data-title attribute\n",
    "                data_title = div[\"data-title\"] if div and \"data-title\" in div.attrs else \"\"\n",
    "\n",
    "                # Extract the question text\n",
    "                p_tag = soup.find('p', class_='card-text')\n",
    "                text_parts = []\n",
    "                if p_tag:\n",
    "                    for element in p_tag.contents:\n",
    "                        if isinstance(element, str):\n",
    "                            text_parts.append(element)\n",
    "                        elif element.name == 'br':\n",
    "                            text_parts.append('\\n')\n",
    "                        elif element.name == 'img':\n",
    "                            text_parts.append(element['src'])\n",
    "                question_str = ''.join(text_parts)\n",
    "\n",
    "                # Extract all answer choices\n",
    "                answer_choices = [\n",
    "                    li.text.strip().replace('\\n', '').replace('\\r', '')\n",
    "                    for li in soup.find_all('li', class_='multi-choice-item')\n",
    "                ]\n",
    "                answer_choices_str = '\\n'.join(answer_choices)\n",
    "\n",
    "                # Combine the data_title, question_str, and answer_choices_str\n",
    "                final_str = f\"{data_title}\\n{question_str}\\n{answer_choices_str}\"\n",
    "\n",
    "                # Process the text to remove extra spaces\n",
    "                lines = final_str.splitlines()\n",
    "                formatted_lines = [\" \".join(line.split()) for line in lines if line.strip()]\n",
    "                formatted_text = \"\\n\".join(formatted_lines)\n",
    "\n",
    "                # Find all badges with \"Highly Voted\"\n",
    "                highly_voted_badges = soup.find_all(\"span\", class_=\"badge badge-primary\")\n",
    "                comment_str = \"\"\n",
    "                for badge in highly_voted_badges:\n",
    "                    if \"Highly Voted\" in badge.text:\n",
    "                        comment_container = badge.find_parent(\"div\", class_=\"comment-container\")\n",
    "                        if comment_container:\n",
    "                            comment_content = comment_container.find(\"div\", class_=\"comment-content\")\n",
    "                            if comment_content:\n",
    "                                comment_str += (\n",
    "                                    \"Highly Voted comment found!\\n\"\n",
    "                                    + comment_content.text.strip()\n",
    "                                    + \"\\n******************************\\n\"\n",
    "                                )\n",
    "\n",
    "                # Combine the formatted text and comment string\n",
    "                final_output = f\"{formatted_text}\\n{comment_str}\"\n",
    "\n",
    "                # Write the final output to the text file\n",
    "                file.write(final_output + \"\\n\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing URL {url}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
